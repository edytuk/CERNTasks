{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Used packages and general settings"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "import re\nimport datetime\nfrom itertools import cycle\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom elasticsearch import Elasticsearch\n\n%matplotlib inline"}, {"cell_type": "markdown", "metadata": {}, "source": "# Elasticsearch configuration"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "username = \"username\"\npassword = \"password\"\nes = Elasticsearch([{\"host\": \"es-cms.cern.ch\", \"port\": 9203, \"http_auth\": username + \":\" + password}], use_ssl=True, verify_certs=True, ca_certs=\"ca-bundle.trust.crt\")"}, {"cell_type": "markdown", "metadata": {}, "source": "# Time filter"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "def time_filter(days=0, until=0):\n    indices = es.cat.indices(index=\"cms-20*\", h=\"index\", request_timeout=600).split(\"\\n\")\n    indices = sorted(indices)\n    indices = [x for x in indices if x != \"\"]\n    if days == 0:\n        return [\"cms-20*\"]\n    today = datetime.date.today()\n    filtered = []\n    datefmt = \"%Y-%m-%d\"\n    for i in indices:\n        date = re.sub(r\"cms-\", \"\", i).rstrip()\n        date = datetime.datetime.strptime(date, datefmt).date()\n        diff = today - date\n        if until <= diff.days < days + until:\n            filtered.append(i.rstrip())\n    return filtered"}, {"cell_type": "markdown", "metadata": {}, "source": "# Indices to be considered"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "no_of_days = 0\nlast_day = 0\nind = time_filter(no_of_days, last_day)\nind = \",\".join(ind)"}, {"cell_type": "markdown", "metadata": {}, "source": "# Part 1"}, {"cell_type": "markdown", "metadata": {}, "source": "Produce a plot of the CPUhrs spent on MINIAOD over the last (say) 12 months and extended also to these task types: AOD, AODSIM, RECO (at least)."}, {"cell_type": "markdown", "metadata": {}, "source": "## Query"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "def query(name_of_task_type):\n    body = {\n        \"size\": 0,\n        \"query\": {\n            \"bool\": {\n                \"must\": [\n                    {\n                        \"match\": {\n                            \"Status\": \"Completed\"\n                        }\n                    },\n                    {\n                        \"range\": {\n                            \"RecordTime\": {\n                                \"gte\": 1483228800000,\n                                \"lte\": 1600000000000,\n                                \"format\": \"epoch_millis\"\n                            }\n                        }\n                    },\n                    {\n                        \"range\": {\n                            \"CpuTimeHr\": {\n                                \"gt\": 0\n                            }\n                        }\n                    },\n                    {\n                        \"match\": {\n                            \"TaskType\": name_of_task_type\n                        }\n                    }\n                ]\n            }\n        },\n        \"aggs\": {\n            \"RecordTime\": {\n                \"date_histogram\": {\n                    \"field\": \"RecordTime\",\n                    \"interval\": \"week\",\n                    \"time_zone\": \"Europe/Berlin\",\n                    \"min_doc_count\": 1\n                },\n                \"aggs\": {\n                    \"CpuTimeHr\": {\n                        \"sum\": {\n                            \"field\": \"CpuTimeHr\"\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    res = es.search(index=ind, body=body, request_timeout=1200)\n\n    return res"}, {"cell_type": "markdown", "metadata": {}, "source": "## Listing of CpuTimeHr"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "def listing_of_cpu_time_hr(buckets):\n    list_of_time_stamps = []\n    list_of_cpu_time_hr = []\n    for bucket in buckets:\n        list_of_time_stamps.append(bucket[\"key\"])\n        list_of_cpu_time_hr.append(bucket[\"CpuTimeHr\"][\"value\"])\n    return list_of_time_stamps, list_of_cpu_time_hr"}, {"cell_type": "markdown", "metadata": {}, "source": "## Function for plotting"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "def plot_cpu_hours(series_of_time, name_of_task_type, style, color, x_from, x_to):\n    plt.rcParams[\"figure.figsize\"] = (25, 10)\n    plt.rcParams.update({\"font.size\": 25})\n    series_of_time.plot(label=name_of_task_type, style=style, color=color)\n    plt.ylabel(\"CPU time hours (sum)\")\n    plt.legend(loc=9, bbox_to_anchor=(1.15, 1.0))\n    plt.xlim([pd.Timestamp(x_from), pd.Timestamp(x_to)])"}, {"cell_type": "markdown", "metadata": {}, "source": "## Graph"}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "trusted": true}, "outputs": [], "source": "date_from = \"2017-01-01\"\ndate_to = \"2018-04-01\"\nstyle = [\"-\", \"--\", \"-.\"]\nstyle_cycler = cycle(style)\ncolors = [\"b\", \"g\"]\ncolors_cycler = cycle(colors)\ntask_types = [\"MINIAOD\", \"AOD\", \"AODSIM\", \"RECO\", \"MINIAODSIM\", \"USER\"]\nfor task_type in task_types:\n    try:\n        res = query(task_type)\n        buckets_of_RecordTime = res[\"aggregations\"][\"RecordTime\"][\"buckets\"]\n        time_stamps, cpu_time_hr = listing_of_cpu_time_hr(buckets_of_RecordTime)\n        time_series = pd.Series(cpu_time_hr, index=pd.to_datetime(time_stamps, unit=\"ms\"))\n        plot_cpu_hours(time_series, task_type, next(style_cycler), next(colors_cycler), date_from, date_to)\n    except TypeError as te:\n        print(\"Oops, found a TypeError for %s. Here it is: %s\" % (task_type, te))"}, {"cell_type": "markdown", "metadata": {}, "source": "# Part 2"}, {"cell_type": "markdown", "metadata": {}, "source": "Produce a plot of the CPUhrs spent on task types."}, {"cell_type": "markdown", "metadata": {}, "source": "## Query"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "body = {\n    \"size\": 0,\n    \"query\": {\n        \"bool\": {\n            \"must\": [\n                {\n                    \"match\": {\n                        \"Status\": \"Completed\"\n                    }\n                },\n                {\n                    \"range\": {\n                        \"RecordTime\": {\n                            \"gte\": 1483228800000,\n                            \"lte\": 1600000000000,\n                            \"format\": \"epoch_millis\"\n                        }\n                    }\n                },\n                {\n                    \"range\": {\n                        \"CpuTimeHr\": {\n                            \"gt\": 0\n                        }\n                    }\n                }\n            ]\n        }\n    },\n    \"aggs\": {\n        \"TaskType\": {\n            \"terms\": {\n                \"field\": \"TaskType\",\n                \"size\": 18\n            },\n            \"aggs\": {\n                \"RecordTime\": {\n                    \"date_histogram\": {\n                        \"field\": \"RecordTime\",\n                        \"interval\": \"week\",\n                        \"time_zone\": \"Europe/Berlin\",\n                        \"min_doc_count\": 1\n                    },\n                    \"aggs\": {\n                        \"CpuTimeHr\": {\n                            \"sum\": {\n                                \"field\": \"CpuTimeHr\"\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\nres = es.search(index=ind, body=body, request_timeout=1200)"}, {"cell_type": "markdown", "metadata": {}, "source": "## Listing of CpuTimeHr for task types"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "time_stamps_dict = {}\ncpu_time_hr_dict = {}\nbuckets_of_TaskType = res[\"aggregations\"][\"TaskType\"][\"buckets\"]\nfor b_TaskType in buckets_of_TaskType:\n    buckets_of_RecordTime = b_TaskType[\"RecordTime\"][\"buckets\"]\n    time_stamps, cpu_time_hr = listing_of_cpu_time_hr(buckets_of_RecordTime)\n    task_type = b_TaskType[\"key\"]\n    time_stamps_dict[task_type] = time_stamps\n    cpu_time_hr_dict[task_type] = cpu_time_hr"}, {"cell_type": "markdown", "metadata": {}, "source": "## Function for plotting"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "scrolled": false, "trusted": true}, "outputs": [], "source": "def plot_cpu_hours_from_dict(dictionary_of_time_stamps, dictionary_of_cpu_time_hr, list_of_styles, list_of_colors):\n    styles_cycler = cycle(list_of_styles)\n    colors_cycler = cycle(list_of_colors)\n    for key in dictionary_of_time_stamps.keys():\n        time_series = pd.Series(dictionary_of_cpu_time_hr[key], index=pd.to_datetime(dictionary_of_time_stamps[key], unit=\"ms\"))\n        plot_cpu_hours(time_series, key, next(styles_cycler), next(colors_cycler), date_from, date_to)"}, {"cell_type": "markdown", "metadata": {}, "source": "## Merging task types by case insensitive names"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "scrolled": true, "trusted": true}, "outputs": [], "source": "def merge_two_lists(list_a, list_b):\n    list_c = dict(list_a)\n    for key, value in list_b:\n        list_c[key] = list_c.get(key, 0) + value\n    list_c = list(list_c.items())\n    list_c = sorted(list_c, key=lambda tup: tup[0])\n    return list_c\n\nbig_dict = {}\nfor key in time_stamps_dict.keys():\n    big_dict[key.upper()] = []\n\nfor key in time_stamps_dict.keys():\n    big_dict[key.upper()].append(zip(time_stamps_dict[key], cpu_time_hr_dict[key]))\n\nfor key in big_dict.keys():\n    while len(big_dict[key]) > 1:\n        last = big_dict[key].pop()\n        penultimate = big_dict[key].pop()\n        big_dict[key].append(merge_two_lists(last, penultimate))\n    big_dict[key] = big_dict[key][0]\n\ntime_stamps_dict = {}\ncpu_time_hr_dict = {}\nfor key in big_dict.keys():\n    time_stamps_dict[key] = [i[0] for i in big_dict[key]]\n    cpu_time_hr_dict[key] = [i[1] for i in big_dict[key]]"}, {"cell_type": "markdown", "metadata": {}, "source": "## Graph"}, {"cell_type": "code", "execution_count": null, "metadata": {"trusted": true}, "outputs": [], "source": "styles = [\"-\", \"--\"]\ncolors = [\"b\", \"g\", \"r\", \"m\", \"y\"]\nplot_cpu_hours_from_dict(time_stamps_dict, cpu_time_hr_dict, styles, colors)"}], "metadata": {"kernelspec": {"display_name": "Python 2", "language": "python", "name": "python2"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 2}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython2", "version": "2.7.13"}}, "nbformat": 4, "nbformat_minor": 2}
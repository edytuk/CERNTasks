{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Used packages and general settings"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "scrolled": true, "trusted": true}, "outputs": [], "source": "import re\nimport datetime\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom elasticsearch import Elasticsearch\n\n%matplotlib inline"}, {"cell_type": "markdown", "metadata": {}, "source": "# Elasticsearch configuration"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "username = \"username\"\npassword = \"password\"\nes = Elasticsearch([{\"host\": \"es-cms.cern.ch\", \"port\": 9203, \"http_auth\": username + \":\" + password}], use_ssl=True, verify_certs=True, ca_certs=\"ca-bundle.trust.crt\")"}, {"cell_type": "markdown", "metadata": {}, "source": "# Time filter"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "def time_filter(days=0, until=0):\n    indices = es.cat.indices(index=\"cms-20*\", h=\"index\", request_timeout=600).split(\"\\n\")\n    indices = sorted(indices)\n    indices = [x for x in indices if x != \"\"]\n    if days == 0:\n        return [\"cms-20*\"]\n    today = datetime.date.today()\n    filtered = []\n    datefmt = \"%Y-%m-%d\"\n    for i in indices:\n        date = re.sub(r\"cms-\", \"\", i).rstrip()\n        date = datetime.datetime.strptime(date, datefmt).date()\n        diff = today - date\n        if until <= diff.days < days + until:\n            filtered.append(i.rstrip())\n    return filtered"}, {"cell_type": "markdown", "metadata": {}, "source": "# Indices to be considered"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "no_of_days = 0\nlast_day = 0\nind = time_filter(no_of_days, last_day)\nind = \",\".join(ind)"}, {"cell_type": "markdown", "metadata": {}, "source": "# Part 1"}, {"cell_type": "markdown", "metadata": {}, "source": "Produce a plot of the overall CPU efficiency of all CMS jobs in few time windows, e.g. the last 1-3-6 months:\n1. for all jobs\n2. for successful jobs only"}, {"cell_type": "markdown", "metadata": {}, "source": "## Query"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "body = {\n    \"size\": 0,\n    \"query\": {\n        \"bool\": {\n            \"must\": [\n                {\n                    \"match\": {\n                        \"Status\": \"Completed\"\n                    }\n                },\n                {\n                    \"range\": {\n                        \"RecordTime\": {\n                            \"gte\": 1483228800000,\n                            \"lte\": 1600000000000,\n                            \"format\": \"epoch_millis\"\n                        }\n                    }\n                },\n                {\n                    \"range\": {\n                        \"CpuTimeHr\": {\n                            \"gt\": 0\n                        }\n                    }\n                },\n                {\n                    \"range\": {\n                        \"CommittedCoreHr\": {\n                            \"gt\": 0\n                        }\n                    }\n                },\n                {\n                    \"exists\": {\n                        \"field\": \"ExitCode\"\n                    }\n                }\n            ]\n        }\n    },\n    \"aggs\": {\n        \"RecordTime\": {\n            \"date_histogram\": {\n                \"field\": \"RecordTime\",\n                \"interval\": \"week\",\n                \"time_zone\": \"Europe/Berlin\",\n                \"min_doc_count\": 1\n            },\n            \"aggs\": {\n                \"ExitCode\": {\n                    \"terms\": {\n                        \"field\": \"ExitCode\",\n                    },\n                    \"aggs\": {\n                        \"CpuTimeHr\": {\n                            \"sum\": {\n                                \"field\": \"CpuTimeHr\"\n                            }\n                        },\n                        \"CommittedCoreHr\": {\n                            \"sum\": {\n                                \"field\": \"CommittedCoreHr\"\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\nres = es.search(index=ind, body=body, request_timeout=1200)"}, {"cell_type": "markdown", "metadata": {}, "source": "## Function for calculation of CPU efficiency"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "def cpu_efficiency_calculation(external_buckets):\n    external_buckets_data = []\n    cpu_eff_of_all_jobs = []\n    cpu_eff_of_successful_jobs = []\n    for external_bucket in external_buckets:\n        external_buckets_data.append(external_bucket[\"key\"])\n        buckets_of_ExitCode = external_bucket[\"ExitCode\"][\"buckets\"]\n        sum_of_CpuTimeHr = 0\n        sum_of_CommittedCoreHr = 0\n        for b_ExitCode in buckets_of_ExitCode:\n            sum_of_CpuTimeHr = sum_of_CpuTimeHr + b_ExitCode[\"CpuTimeHr\"][\"value\"]\n            sum_of_CommittedCoreHr = sum_of_CommittedCoreHr + b_ExitCode[\"CommittedCoreHr\"][\"value\"]\n            if b_ExitCode[\"key\"] == 0:\n                cpu_eff_of_successful_jobs.append(b_ExitCode[\"CpuTimeHr\"][\"value\"] / b_ExitCode[\"CommittedCoreHr\"][\"value\"] * 100)\n        cpu_eff_of_all_jobs.append(sum_of_CpuTimeHr / sum_of_CommittedCoreHr * 100)\n\n    return external_buckets_data, cpu_eff_of_all_jobs, cpu_eff_of_successful_jobs"}, {"cell_type": "markdown", "metadata": {}, "source": "## Calculation of CPU efficiency"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "buckets_of_RecordTime = res[\"aggregations\"][\"RecordTime\"][\"buckets\"]\ntime_stamps, cpu_eff_for_all_jobs, cpu_eff_for_successful_jobs = cpu_efficiency_calculation(buckets_of_RecordTime)"}, {"cell_type": "markdown", "metadata": {}, "source": "## Time series"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "time_series_for_all_jobs = pd.Series(cpu_eff_for_all_jobs, index=pd.to_datetime(time_stamps, unit=\"ms\"))\ntime_series_for_successful_jobs = pd.Series(cpu_eff_for_successful_jobs, index=pd.to_datetime(time_stamps, unit=\"ms\"))"}, {"cell_type": "markdown", "metadata": {}, "source": "## Function for ploting a graph of CPU efficiency"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "scrolled": false, "trusted": true}, "outputs": [], "source": "def plot_cpu_eff_for_all_task_types(x_from, x_to):\n    time_series_for_all_jobs.plot(style=\"r\", label=\"all jobs\")\n    time_series_for_successful_jobs.plot(style=\"b\", label=\"successful jobs\")\n    plt.legend(loc=9, bbox_to_anchor=(1.22, 0.6))\n    plt.ylabel(\"CPU efficiency (%)\")\n    plt.xlim([pd.Timestamp(x_from), pd.Timestamp(x_to)])"}, {"cell_type": "markdown", "metadata": {}, "source": "## Graph of CPU efficiency"}, {"cell_type": "code", "execution_count": null, "metadata": {"trusted": true}, "outputs": [], "source": "date_from = \"2017-01-01\"\ndate_to = \"2018-04-01\"\nplot_cpu_eff_for_all_task_types(date_from, date_to)"}, {"cell_type": "markdown", "metadata": {}, "source": "# Part 2"}, {"cell_type": "markdown", "metadata": {}, "source": "Rank sites for CPU efficiency:\n1. for all jobs\n2. for successful jobs only"}, {"cell_type": "markdown", "metadata": {}, "source": "## Query"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "body = {\n    \"size\": 0,\n    \"query\": {\n        \"bool\": {\n            \"must\": [\n                {\n                    \"match\": {\n                        \"Status\": \"Completed\"\n                    }\n                },\n                {\n                    \"range\": {\n                        \"CpuTimeHr\": {\n                            \"gt\": 0\n                        }\n                    }\n                },\n                {\n                    \"range\": {\n                        \"CommittedCoreHr\": {\n                            \"gt\": 0\n                        }\n                    }\n                },\n                {\n                    \"exists\": {\n                        \"field\": \"ExitCode\"\n                    }\n                },\n                {\n                    \"range\": {\n                        \"RecordTime\": {\n                            \"gte\": 1498860000000,\n                            \"format\": \"epoch_millis\"\n                        }\n                    }\n                }\n            ]\n        }\n    },\n    \"aggs\": {\n        \"Sites\": {\n            \"terms\": {\n                \"field\": \"Site\",\n                \"size\": 100\n            },\n            \"aggs\": {\n                \"ExitCode\": {\n                    \"terms\": {\n                        \"field\": \"ExitCode\",\n                    },\n                    \"aggs\": {\n                        \"CpuTimeHr\": {\n                            \"sum\": {\n                                \"field\": \"CpuTimeHr\"\n                            }\n                        },\n                        \"CommittedCoreHr\": {\n                            \"sum\": {\n                                \"field\": \"CommittedCoreHr\"\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\nres = es.search(index=ind, body=body, request_timeout=1200)"}, {"cell_type": "markdown", "metadata": {}, "source": "## Calculation of CPU efficiency"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "buckets_of_Sites = res[\"aggregations\"][\"Sites\"][\"buckets\"]\nsites, cpu_eff_for_all_jobs, cpu_eff_for_successful_jobs = cpu_efficiency_calculation(buckets_of_Sites)"}, {"cell_type": "markdown", "metadata": {}, "source": "## Function for merging by case insensitive names"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "def merging_by_case_insensitive_names(main_list, list_a, list_b):\n    main_list_upper_case = [x.upper() for x in main_list]\n    dict_a = {}\n    dict_b = {}\n    numbers_of_merging_dict = {}\n    for i in range(0, len(main_list_upper_case)):\n        element = main_list_upper_case[i]\n        if element in dict_a.keys():\n            dict_a[element] = dict_a[element] + list_a[i]\n            dict_b[element] = dict_b[element] + list_b[i]\n            numbers_of_merging_dict[element] = numbers_of_merging_dict[element] + 1\n        else:\n            dict_a[element] = list_a[i]\n            dict_b[element] = list_b[i]\n            numbers_of_merging_dict[element] = 1\n    main_list_merged = list(dict_a.keys())\n    list_a_merged = list(dict_a.values())\n    list_b_merged = list(dict_b.values())\n    numbers_of_merging = list(numbers_of_merging_dict.values())\n\n    return main_list_merged, list_a_merged, list_b_merged, numbers_of_merging"}, {"cell_type": "markdown", "metadata": {}, "source": "## Merging sites by case insensitive names"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "sites_merged, cpu_eff_for_all_jobs_merged, cpu_eff_for_successful_jobs_merged, merging_numbers = merging_by_case_insensitive_names(sites, cpu_eff_for_all_jobs, cpu_eff_for_successful_jobs)\nfor i in range(0, len(cpu_eff_for_all_jobs_merged)):\n    cpu_eff_for_all_jobs_merged[i] = cpu_eff_for_all_jobs_merged[i] / merging_numbers[i]\n    cpu_eff_for_successful_jobs_merged[i] = cpu_eff_for_successful_jobs_merged[i] / merging_numbers[i]"}, {"cell_type": "markdown", "metadata": {}, "source": "## Sorting by CPU efficiency for all jobs"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "sites = sites_merged\ncpu_eff_for_all_jobs = cpu_eff_for_all_jobs_merged\ncpu_eff_for_successful_jobs = cpu_eff_for_successful_jobs_merged\nlist_to_sort = []\nfor i in range(len(sites)):\n    list_to_sort.append((sites[i], cpu_eff_for_all_jobs[i], cpu_eff_for_successful_jobs[i]))\nordered_list = sorted(list_to_sort, key=lambda site: site[1], reverse=True)\nsites = [i[0] for i in ordered_list]\ncpu_eff_for_all_jobs = [i[1] for i in ordered_list]\ncpu_eff_for_successful_jobs = [i[2] for i in ordered_list]"}, {"cell_type": "markdown", "metadata": {}, "source": "## Function for plotting a graph of CPU efficiency"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "def plot_cpu_eff_for_all_sites(x_data, y_data_a, y_data_b, index, title=\"\"):\n    plt.rcParams[\"figure.figsize\"] = (50, 10)\n    plt.rcParams.update({\"font.size\": 25})\n    index = np.arange(len(index))\n    bar_width = 0.35\n    opacity = 0.8\n    plt.bar(index, y_data_a, bar_width, alpha=opacity, align=\"center\", color=\"b\", label=\"all jobs\")\n    plt.bar(index + bar_width, y_data_b, bar_width, alpha=opacity, align=\"center\", color=\"g\", label=\"successful jobs\")\n    plt.xticks(index + bar_width * 0.5, x_data, rotation=90)\n    plt.legend(loc=9, bbox_to_anchor=(1.07, 0.6))\n    plt.margins(0.005, 0.005)\n    plt.title(\"CPU efficiency by sites\" + title)\n    plt.ylabel(\"CPU efficiency\")\n    plt.ylim([0, 100])\n    plt.show()"}, {"cell_type": "markdown", "metadata": {}, "source": "## Function for plotting a histogram of CPU efficiency"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "def histogram(cpu_eff, title):\n    y_values, _, _ = plt.hist(cpu_eff, bins=100, range=[0, 100])\n    plt.title(title)\n    plt.ylim([0, y_values.max() + 1])\n    plt.xlabel(\"CPU efficiency\")\n    plt.ylabel(\"Frequency\")\n    plt.show()"}, {"cell_type": "markdown", "metadata": {}, "source": "## Graphs of CPU efficiency"}, {"cell_type": "code", "execution_count": null, "metadata": {"trusted": true}, "outputs": [], "source": "plot_cpu_eff_for_all_sites(sites, cpu_eff_for_all_jobs, cpu_eff_for_successful_jobs, sites)\nhistogram(cpu_eff_for_all_jobs, \"All jobs\")\nhistogram(cpu_eff_for_successful_jobs, \"Successful jobs\")"}, {"cell_type": "markdown", "metadata": {"collapsed": true}, "source": "# Part 3"}, {"cell_type": "markdown", "metadata": {}, "source": "Rank the task types by cumulative wall-clock time:\n1. \u201cTask types\u201d = e.g. GENSIM, DIGI, RECO, etc."}, {"cell_type": "markdown", "metadata": {}, "source": "## Query"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "body = {\n    \"size\": 0,\n    \"query\": {\n        \"bool\": {\n            \"must\": [\n                {\n                    \"match\": {\n                        \"Status\": \"Completed\"\n                    }\n                },\n                {\n                    \"range\": {\n                        \"RequestCpus\": {\n                            \"gt\": 0\n                        }\n                    }\n                },\n                {\n                    \"range\": {\n                        \"CommittedCoreHr\": {\n                            \"gt\": 0\n                        }\n                    }\n                },\n                {\n                    \"range\": {\n                        \"RecordTime\": {\n                            \"gte\": 1498860000000,\n                            \"format\": \"epoch_millis\"\n                        }\n                    }\n                }\n            ]\n        }\n    },\n    \"aggs\": {\n        \"TaskType\": {\n            \"terms\": {\n                \"field\": \"TaskType\",\n                \"size\": 100\n            },\n            \"aggs\": {\n                \"RequestCpus\": {\n                    \"sum\": {\n                        \"field\": \"RequestCpus\"\n                    }\n                },\n                \"CommittedCoreHr\": {\n                    \"sum\": {\n                        \"field\": \"CommittedCoreHr\"\n                    }\n                },\n                \"CoreHr\": {\n                    \"sum\": {\n                        \"field\": \"CoreHr\"\n                    }\n                }\n            }\n        }\n    }\n}\n\nres = es.search(index=ind, body=body, request_timeout=1200)"}, {"cell_type": "markdown", "metadata": {}, "source": "## Listing the wall-clock"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "task_types = []\nwall_clock = []\nwall_clock_CoreHr = []\nbuckets = res[\"aggregations\"][\"TaskType\"][\"buckets\"]\nfor b in buckets:\n    task_types.append(b[\"key\"])\n    wall_clock.append(b[\"CommittedCoreHr\"][\"value\"] / b[\"RequestCpus\"][\"value\"])\n    wall_clock_CoreHr.append(b[\"CoreHr\"][\"value\"])"}, {"cell_type": "markdown", "metadata": {}, "source": "## Merging task types by case insensitive names"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "task_types_merged, wall_clock_merged, wall_clock_CoreHr_merged, merging_numbers = merging_by_case_insensitive_names(task_types, wall_clock, wall_clock_CoreHr)\nfor i in range(0, len(wall_clock_merged)):\n    wall_clock_merged[i] = wall_clock_merged[i] / merging_numbers[i]"}, {"cell_type": "markdown", "metadata": {}, "source": "## Function for plotting a graph of wall-clock"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "def plot_wall_clock(list_of_task_types, list_of_wall_clock, ylabel):\n    plt.rcParams['figure.figsize'] = (50, 10)\n    plt.rcParams.update({\"font.size\": 25})\n    task_types_by_wall_clock = dict(zip(list_of_task_types, list_of_wall_clock))\n    task_types_by_wall_clock_df = pd.DataFrame.from_dict(task_types_by_wall_clock, orient=\"index\")\n    task_types_by_wall_clock_df = task_types_by_wall_clock_df.sort_values(by=[0], ascending=False)\n    total_sum_of_wall_clock = sum(task_types_by_wall_clock_df[0])\n    sum_of_wall_clock = 0\n    number_of_data = 0\n    for i in range(0, len(task_types_by_wall_clock_df)):\n        sum_of_wall_clock = sum_of_wall_clock + task_types_by_wall_clock_df[0][i]\n        if sum_of_wall_clock / total_sum_of_wall_clock < 0.9:\n            number_of_data = number_of_data + 1\n        else:\n            number_of_data = number_of_data + 1\n            break\n    task_types_by_wall_clock_df[:number_of_data].plot(kind=\"bar\", legend=None)\n    plt.ylabel(ylabel)\n    plt.title(\"Wall-clock by task types\")\n    plt.show()"}, {"cell_type": "markdown", "metadata": {}, "source": "## Graphs of wall-clock"}, {"cell_type": "code", "execution_count": null, "metadata": {"trusted": true}, "outputs": [], "source": "plot_wall_clock(task_types_merged, wall_clock_merged, \"Wall-clock (average of hours for one core)\")\nplot_wall_clock(task_types_merged, wall_clock_CoreHr_merged, \"Wall-clock (sum of hours)\")"}, {"cell_type": "markdown", "metadata": {}, "source": "# Part 4"}, {"cell_type": "markdown", "metadata": {}, "source": "Try to do point 2 above on each of point 3 above:\n1. filter the task types that globally account for > 90% of the total wallclock time (as from point 3) and do point 2 for each of them.\n"}, {"cell_type": "markdown", "metadata": {"collapsed": true}, "source": "## Function for finding task types, wich will be considered"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "def considered_task_types(list_of_task_types_merged, list_of_wall_clock_merged):\n    list_to_sort = []\n    for i in range(len(list_of_task_types_merged)):\n        list_to_sort.append((list_of_task_types_merged[i], list_of_wall_clock_merged[i]))\n    ordered_list = sorted(list_to_sort, key=lambda task_type: task_type[1], reverse=True)\n    task_types_sorted = [i[0] for i in ordered_list]\n    wall_clock_sorted = [i[1] for i in ordered_list]\n    total_wall_clock = sum(wall_clock_sorted)\n    considered_task_types = []\n    sum_of_wall_clock = 0\n    for i in range(len(task_types_sorted)):\n        sum_of_wall_clock = sum_of_wall_clock + wall_clock_sorted[i] / total_wall_clock\n        if sum_of_wall_clock < 0.9:\n            considered_task_types.append(task_types_sorted[i])\n        else:\n            break\n    task_types_temporary = []\n    for i in range(0, len(task_types)):\n        for j in range(0, len(considered_task_types)):\n            if task_types[i].upper() == considered_task_types[j]:\n                task_types_temporary.append(task_types[i])\n                break\n    task_types_query = []\n    for task_type in task_types_temporary:\n        task_types_query.append({\"term\": {\"TaskType\": task_type}})\n    return task_types_query"}, {"cell_type": "markdown", "metadata": {}, "source": "##  Considered task types"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "task_types_for_query_wall_clock = considered_task_types(task_types_merged, wall_clock_merged)\ntask_types_for_query_wall_clock_CoreHr = considered_task_types(task_types_merged, wall_clock_CoreHr_merged)"}, {"cell_type": "markdown", "metadata": {}, "source": "## Function for query"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "scrolled": true, "trusted": true}, "outputs": [], "source": "def make_query_for_wall_clock(names_of_task_types):\n    body = {\n        \"size\": 0,\n        \"query\": {\n            \"constant_score\": {\n                \"filter\": {\n                    \"bool\": {\n                        \"must\": [\n                            {\n                                \"match\": {\n                                    \"Status\": \"Completed\"\n                                }\n                            },\n                            {\n                                \"range\": {\n                                    \"CpuTimeHr\": {\n                                        \"gt\": 0\n                                    }\n                                }\n                            },\n                            {\n                                \"range\": {\n                                    \"CommittedCoreHr\": {\n                                        \"gt\": 0\n                                    }\n                                }\n                            },\n                            {\n                                \"exists\": {\n                                    \"field\": \"ExitCode\"\n                                }\n                            },\n                            {\n                                \"range\": {\n                                    \"RecordTime\": {\n                                        \"gte\": 1498860000000,\n                                        \"format\": \"epoch_millis\"\n                                    }\n                                }\n                            }\n                        ],\n                        \"should\": names_of_task_types\n                    }\n                }\n            }\n        },\n        \"aggs\": {\n            \"TaskType\": {\n                \"terms\": {\n                    \"field\": \"TaskType\",\n                    \"size\": len(names_of_task_types)\n                },\n                \"aggs\": {\n                    \"Sites\": {\n                        \"terms\": {\n                            \"field\": \"Site\",\n                            \"size\": 100\n                        },\n                        \"aggs\": {\n                            \"ExitCode\": {\n                                \"terms\": {\n                                    \"field\": \"ExitCode\",\n                                },\n                                \"aggs\": {\n                                    \"CpuTimeHr\": {\n                                        \"sum\": {\n                                            \"field\": \"CpuTimeHr\"\n                                        }\n                                    },\n                                    \"CommittedCoreHr\": {\n                                        \"sum\": {\n                                            \"field\": \"CommittedCoreHr\"\n                                        }\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n    res = es.search(index=ind, body=body, request_timeout=1200)\n\n    return res"}, {"cell_type": "markdown", "metadata": {}, "source": "## Queries for wall-clock"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "res_wall_clock = make_query_for_wall_clock(task_types_for_query_wall_clock)\nres_wall_clock_CoreHr = make_query_for_wall_clock(task_types_for_query_wall_clock_CoreHr)"}, {"cell_type": "markdown", "metadata": {}, "source": "## Function for calculiation of CPU efficiency and plotting a graph of CPU efficiency for wall-clock"}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "source": "def calculate_and_plot_cpu_eff(res):\n    task_types_dic = {}\n    buckets_of_TaskType = res[\"aggregations\"][\"TaskType\"][\"buckets\"]\n    for b_TaskType in buckets_of_TaskType:\n        sites = []\n        cpu_eff_for_all_jobs = []\n        cpu_eff_for_successful_jobs = []\n        sites_dict = {}\n        task_type = b_TaskType[\"key\"]\n        buckets_of_Sites = b_TaskType[\"Sites\"][\"buckets\"]\n        for b_Sites in buckets_of_Sites:\n            buckets_of_ExitCode = b_Sites[\"ExitCode\"][\"buckets\"]\n            sum_of_CpuTimeHr = 0\n            sum_of_CommittedCoreHr = 0\n            for b_ExitCode in buckets_of_ExitCode:\n                sum_of_CpuTimeHr = sum_of_CpuTimeHr + b_ExitCode[\"CpuTimeHr\"][\"value\"]\n                sum_of_CommittedCoreHr = sum_of_CommittedCoreHr + b_ExitCode[\"CommittedCoreHr\"][\"value\"]\n                if b_ExitCode[\"key\"] == 0:\n                    cpu_eff_for_successful_jobs.append(b_ExitCode[\"CpuTimeHr\"][\"value\"] / b_ExitCode[\"CommittedCoreHr\"][\"value\"] * 100)\n            if len(cpu_eff_for_successful_jobs) != len(cpu_eff_for_all_jobs):\n                cpu_eff_for_all_jobs.append(sum_of_CpuTimeHr / sum_of_CommittedCoreHr * 100)\n                sites.append(b_Sites[\"key\"])\n                site_upper_case = b_Sites[\"key\"].upper()\n                if site_upper_case in sites_dict.keys():\n                    sites_dict[site_upper_case] = (sites_dict[site_upper_case][0] + cpu_eff_for_all_jobs[-1], sites_dict[site_upper_case][1] + cpu_eff_for_successful_jobs[-1], sites_dict[site_upper_case][2] + 1)\n                else:\n                    sites_dict[site_upper_case] = (cpu_eff_for_all_jobs[-1], cpu_eff_for_successful_jobs[-1], 1)\n        task_type_upper_case = task_type.upper()\n        if task_type_upper_case in task_types_dic.keys():\n            for key in sites_dict.keys():\n                if key in task_types_dic[task_type_upper_case].keys():\n                    task_types_dic[task_type_upper_case][key] = (task_types_dic[task_type_upper_case][key][0] + sites_dict[key][0], task_types_dic[task_type_upper_case][key][1] + sites_dict[key][1], task_types_dic[task_type_upper_case][key][2] + sites_dict[key][2])\n                else:\n                    task_types_dic[task_type_upper_case][key] = sites_dict[key]\n        else:\n            task_types_dic[task_type_upper_case] = sites_dict\n    for task_type_key, task_type_value in task_types_dic.iteritems():\n        list_to_sort = []\n        for site_key, site_value in task_type_value.iteritems():\n            list_to_sort.append((site_key, site_value[0] / site_value[2], site_value[1] / site_value[2]))\n        ordered_list = sorted(list_to_sort, key=lambda site: site[1], reverse=True)\n        sites = [i[0] for i in ordered_list]\n        cpu_eff_for_all_jobs = [i[1] for i in ordered_list]\n        cpu_eff_for_successful_jobs = [i[2] for i in ordered_list]\n        plot_cpu_eff_for_all_sites(sites, cpu_eff_for_all_jobs, cpu_eff_for_successful_jobs, task_type_value, \" for \" + task_type_key)\n        histogram(cpu_eff_for_all_jobs, \"CPU efficiency by sites for \" + task_type_key + \" (all jobs)\")\n        histogram(cpu_eff_for_successful_jobs, \"CPU efficiency by sites for \" + task_type_key + \" (successful jobs)\")"}, {"cell_type": "markdown", "metadata": {}, "source": "## Calculiation of CPU efficiency and plotting graphs of CPU efficiency for wall-clock (average of hours for one core)"}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "trusted": true}, "outputs": [], "source": "calculate_and_plot_cpu_eff(res_wall_clock)"}, {"cell_type": "markdown", "metadata": {}, "source": "## Calculiation of CPU efficiency and plotting graphs of CPU efficiency for wall-clock (sum of hours)"}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "trusted": true}, "outputs": [], "source": "calculate_and_plot_cpu_eff(res_wall_clock_CoreHr)"}], "metadata": {"kernelspec": {"display_name": "Python 2", "language": "python", "name": "python2"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 2}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython2", "version": "2.7.13"}}, "nbformat": 4, "nbformat_minor": 2}